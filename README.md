**📖 Advanced RAG with LangChain + Groq + Chroma**
🔥 Overview

This repository contains an Advanced Retrieval-Augmented Generation (RAG) pipeline built using:

1.LangChain for orchestration

2.Groq LLMs for blazing fast inference

3.Chroma as the persistent vector database

4.HuggingFace embeddings for semantic search

The pipeline can:
✅ Load and process multiple PDFs
✅ Store embeddings in a persistent vector DB
✅ Perform conversational Q&A with memory
✅ Provide citations/sources for transparencys






  ***✨Features***

1.📂 Load and process multiple PDFs

2.🔎 Split documents into chunks for efficient retrieval

3.💾 Store embeddings in Chroma (persistent vector DB)

4.🧠 Keep track of chat history with memory

5.📑 Retrieve citations for every answer

6.⚡ Interactive Q&A loop




**⚙️ Setup**

Get a Groq API Key from Groq Console
.

Set the key as an environment variable:export GROQ_API_KEY="your_api_key_here"


