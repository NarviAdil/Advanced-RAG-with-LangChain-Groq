**ğŸ“– Advanced RAG with LangChain + Groq + Chroma**
ğŸ”¥ Overview

This repository contains an Advanced Retrieval-Augmented Generation (RAG) pipeline built using:

1.LangChain for orchestration

2.Groq LLMs for blazing fast inference

3.Chroma as the persistent vector database

4.HuggingFace embeddings for semantic search

The pipeline can:
âœ… Load and process multiple PDFs
âœ… Store embeddings in a persistent vector DB
âœ… Perform conversational Q&A with memory
âœ… Provide citations/sources for transparencys






  ***âœ¨Features***

1.ğŸ“‚ Load and process multiple PDFs

2.ğŸ” Split documents into chunks for efficient retrieval

3.ğŸ’¾ Store embeddings in Chroma (persistent vector DB)

4.ğŸ§  Keep track of chat history with memory

5.ğŸ“‘ Retrieve citations for every answer

6.âš¡ Interactive Q&A loop




**âš™ï¸ Setup**

Get a Groq API Key from Groq Console
.

Set the key as an environment variable:export GROQ_API_KEY="your_api_key_here"


